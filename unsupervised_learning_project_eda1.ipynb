{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'status', 'sex', 'orientation', 'body_type', 'diet', 'drinks',\n",
       "       'drugs', 'education', 'ethnicity', 'height', 'income', 'job',\n",
       "       'last_online', 'location', 'offspring', 'pets', 'religion', 'sign',\n",
       "       'smokes', 'speaks', 'essay0', 'essay1', 'essay2', 'essay3', 'essay4',\n",
       "       'essay5', 'essay6', 'essay7', 'essay8', 'essay9'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Read in data\n",
    "ok_cupid_df = pd.read_csv('data/okcupid_profiles.csv')\n",
    "ok_cupid_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Gather data, determine the method of data collection and provenance of the data\n",
    "\n",
    "I obtained the heart disease dataset from kaggle here: https://www.kaggle.com/datasets/andrewmvd/okcupid-profiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Identify a Supervised Machine Learning Problem\n",
    "\n",
    "This project explores the OkCupid dataset in which I try to answer if I can find meaningful clusters of users and answer the following questions:\n",
    "\n",
    "1. Is there a lot of variety of people which OkCupid markets to its users or is everybody the same\n",
    "2. Are there distinct groups on OkCupid in which the users can be separated into?\n",
    "\n",
    "I extracted the OkCupid dataset from Kaggle in CSV format. The single .csv file was used throughout my entire project. Age, income, and height were the only numeric features, and all others being type object.\n",
    "\n",
    "For this dataset, I will be using clustering techniques to understand the different kinds of users in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Exploratory Data Analysis (EDA) â€” Inspect, Visualize and Clean the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Describe the factors or components that make up the dataset (The \"factors\" here are called \"features\" in the machine learning term. These factors are often columns in the tabulated data). For each factor, use a box-plot, scatter plot, histogram, etc., to describe the data distribution as appropriate.\n",
    "\n",
    "The features of this dataset are:\n",
    "\n",
    "- age\n",
    "- status\n",
    "- sex\n",
    "- orientation\n",
    "- body_type\n",
    "- diet\n",
    "- drinks\n",
    "- drugs\n",
    "- education\n",
    "- ethnicity\n",
    "- height\n",
    "- income\n",
    "- job\n",
    "- last_online\n",
    "- location\n",
    "- offspring\n",
    "- pets\n",
    "- religion\n",
    "- sign\n",
    "- smokes\n",
    "- speaks\n",
    "- essay0, essay1, essay2, essay3, essay4, essay5, essay6, essay7, essay8, essay9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The OkCupid dataset has many rows and columns with missing values (i.e. null). The features income, and offspring will be completely removed as they had over 59% missing values or values which were out of range (income: -1).\n",
    "\n",
    "1. smokes, drinks, education, body_type, and drugs will be label encoded (i.e. doing drugs is 1, not doing drugs is 0)\n",
    "\n",
    "2. religion, speaks, diet, and sign will be transformed using CountVectorizer as well as some form of label encoding. All three of these features have either a level of seriousness or fluency which cannot not be ignored. For example, fluent in English is 3, poorly is 0. Seriousness about religion has a higher score versus not serious.\n",
    "\n",
    "- ethnicity, all essay columns, and pets also transformed using CountVectorizer (for pets only likes pet X, and has pet X were kept)\n",
    "- For essays, the length of essay also turned into a feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(59946, 31)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check shape\n",
    "ok_cupid_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 59946 entries, 0 to 59945\n",
      "Data columns (total 31 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   age          59946 non-null  int64  \n",
      " 1   status       59946 non-null  object \n",
      " 2   sex          59946 non-null  object \n",
      " 3   orientation  59946 non-null  object \n",
      " 4   body_type    54650 non-null  object \n",
      " 5   diet         35551 non-null  object \n",
      " 6   drinks       56961 non-null  object \n",
      " 7   drugs        45866 non-null  object \n",
      " 8   education    53318 non-null  object \n",
      " 9   ethnicity    54266 non-null  object \n",
      " 10  height       59943 non-null  float64\n",
      " 11  income       59946 non-null  int64  \n",
      " 12  job          51748 non-null  object \n",
      " 13  last_online  59946 non-null  object \n",
      " 14  location     59946 non-null  object \n",
      " 15  offspring    24385 non-null  object \n",
      " 16  pets         40025 non-null  object \n",
      " 17  religion     39720 non-null  object \n",
      " 18  sign         48890 non-null  object \n",
      " 19  smokes       54434 non-null  object \n",
      " 20  speaks       59896 non-null  object \n",
      " 21  essay0       54458 non-null  object \n",
      " 22  essay1       52374 non-null  object \n",
      " 23  essay2       50308 non-null  object \n",
      " 24  essay3       48470 non-null  object \n",
      " 25  essay4       49409 non-null  object \n",
      " 26  essay5       49096 non-null  object \n",
      " 27  essay6       46175 non-null  object \n",
      " 28  essay7       47495 non-null  object \n",
      " 29  essay8       40721 non-null  object \n",
      " 30  essay9       47343 non-null  object \n",
      "dtypes: float64(1), int64(2), object(28)\n",
      "memory usage: 14.2+ MB\n"
     ]
    }
   ],
   "source": [
    "ok_cupid_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>status</th>\n",
       "      <th>sex</th>\n",
       "      <th>orientation</th>\n",
       "      <th>body_type</th>\n",
       "      <th>diet</th>\n",
       "      <th>drinks</th>\n",
       "      <th>drugs</th>\n",
       "      <th>education</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>...</th>\n",
       "      <th>essay0</th>\n",
       "      <th>essay1</th>\n",
       "      <th>essay2</th>\n",
       "      <th>essay3</th>\n",
       "      <th>essay4</th>\n",
       "      <th>essay5</th>\n",
       "      <th>essay6</th>\n",
       "      <th>essay7</th>\n",
       "      <th>essay8</th>\n",
       "      <th>essay9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>a little extra</td>\n",
       "      <td>strictly anything</td>\n",
       "      <td>socially</td>\n",
       "      <td>never</td>\n",
       "      <td>working on college/university</td>\n",
       "      <td>asian, white</td>\n",
       "      <td>...</td>\n",
       "      <td>about me:  i would love to think that i was so...</td>\n",
       "      <td>currently working as an international agent fo...</td>\n",
       "      <td>making people laugh. ranting about a good salt...</td>\n",
       "      <td>the way i look. i am a six foot half asian, ha...</td>\n",
       "      <td>books: absurdistan, the republic, of mice and ...</td>\n",
       "      <td>food. water. cell phone. shelter.</td>\n",
       "      <td>duality and humorous things</td>\n",
       "      <td>trying to find someone to hang out with. i am ...</td>\n",
       "      <td>i am new to california and looking for someone...</td>\n",
       "      <td>you want to be swept off your feet! you are ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35</td>\n",
       "      <td>single</td>\n",
       "      <td>m</td>\n",
       "      <td>straight</td>\n",
       "      <td>average</td>\n",
       "      <td>mostly other</td>\n",
       "      <td>often</td>\n",
       "      <td>sometimes</td>\n",
       "      <td>working on space camp</td>\n",
       "      <td>white</td>\n",
       "      <td>...</td>\n",
       "      <td>i am a chef: this is what that means. 1. i am ...</td>\n",
       "      <td>dedicating everyday to being an unbelievable b...</td>\n",
       "      <td>being silly. having ridiculous amonts of fun w...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am die hard christopher moore fan. i don't r...</td>\n",
       "      <td>delicious porkness in all of its glories. my b...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>i am very open and will share just about anyth...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  status sex orientation       body_type               diet    drinks  \\\n",
       "0   22  single   m    straight  a little extra  strictly anything  socially   \n",
       "1   35  single   m    straight         average       mostly other     often   \n",
       "\n",
       "       drugs                      education     ethnicity  ...  \\\n",
       "0      never  working on college/university  asian, white  ...   \n",
       "1  sometimes          working on space camp         white  ...   \n",
       "\n",
       "                                              essay0  \\\n",
       "0  about me:  i would love to think that i was so...   \n",
       "1  i am a chef: this is what that means. 1. i am ...   \n",
       "\n",
       "                                              essay1  \\\n",
       "0  currently working as an international agent fo...   \n",
       "1  dedicating everyday to being an unbelievable b...   \n",
       "\n",
       "                                              essay2  \\\n",
       "0  making people laugh. ranting about a good salt...   \n",
       "1  being silly. having ridiculous amonts of fun w...   \n",
       "\n",
       "                                              essay3  \\\n",
       "0  the way i look. i am a six foot half asian, ha...   \n",
       "1                                                NaN   \n",
       "\n",
       "                                              essay4  \\\n",
       "0  books: absurdistan, the republic, of mice and ...   \n",
       "1  i am die hard christopher moore fan. i don't r...   \n",
       "\n",
       "                                              essay5  \\\n",
       "0                  food. water. cell phone. shelter.   \n",
       "1  delicious porkness in all of its glories. my b...   \n",
       "\n",
       "                        essay6  \\\n",
       "0  duality and humorous things   \n",
       "1                          NaN   \n",
       "\n",
       "                                              essay7  \\\n",
       "0  trying to find someone to hang out with. i am ...   \n",
       "1                                                NaN   \n",
       "\n",
       "                                              essay8  \\\n",
       "0  i am new to california and looking for someone...   \n",
       "1  i am very open and will share just about anyth...   \n",
       "\n",
       "                                              essay9  \n",
       "0  you want to be swept off your feet! you are ti...  \n",
       "1                                                NaN  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok_cupid_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill income column containing -1 with null (to determine null values)\n",
    "ok_cupid_df.loc[ok_cupid_df['income'] == -1, 'income'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age             0.00\n",
       "status          0.00\n",
       "sex             0.00\n",
       "orientation     0.00\n",
       "body_type       8.83\n",
       "diet           40.69\n",
       "drinks          4.98\n",
       "drugs          23.49\n",
       "education      11.06\n",
       "ethnicity       9.48\n",
       "height          0.01\n",
       "income         80.81\n",
       "job            13.68\n",
       "last_online     0.00\n",
       "location        0.00\n",
       "offspring      59.32\n",
       "pets           33.23\n",
       "religion       33.74\n",
       "sign           18.44\n",
       "smokes          9.19\n",
       "speaks          0.08\n",
       "essay0          9.15\n",
       "essay1         12.63\n",
       "essay2         16.08\n",
       "essay3         19.14\n",
       "essay4         17.58\n",
       "essay5         18.10\n",
       "essay6         22.97\n",
       "essay7         20.77\n",
       "essay8         32.07\n",
       "essay9         21.02\n",
       "dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check percentage of null values\n",
    "round(ok_cupid_df.isna().sum()/ok_cupid_df.shape[0]*100,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refill income null back with -1\n",
    "ok_cupid_df['income'] = ok_cupid_df['income'].fillna(-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fill null values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "never            37724\n",
       "unknown_drugs    14080\n",
       "sometimes         7732\n",
       "often              410\n",
       "Name: drugs, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drugs\n",
    "ok_cupid_df['drugs'] = ok_cupid_df['drugs'].fillna('unknown_drugs')\n",
    "ok_cupid_df['drugs'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find index where drug value is unknown an drop it from rows\n",
    "index_drugs = ok_cupid_df[ok_cupid_df['drugs'] == 'unknown_drugs'].index\n",
    "ok_cupid_df.drop(index_drugs, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown_diet           18560\n",
       "mostly anything        13105\n",
       "anything                4805\n",
       "strictly anything       3653\n",
       "mostly vegetarian       2530\n",
       "mostly other             785\n",
       "strictly vegetarian      698\n",
       "vegetarian               450\n",
       "strictly other           333\n",
       "other                    257\n",
       "mostly vegan             252\n",
       "strictly vegan           182\n",
       "vegan                     96\n",
       "mostly kosher             70\n",
       "mostly halal              41\n",
       "strictly kosher           15\n",
       "strictly halal            15\n",
       "halal                     10\n",
       "kosher                     9\n",
       "Name: diet, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Diet\n",
    "# fill null diet with unknown\n",
    "ok_cupid_df['diet'] = ok_cupid_df['diet'].fillna('unknown_diet')\n",
    "ok_cupid_df['diet'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Fill unknown_diet based on essay columns:\n",
    "It occured to me that I can possibly fill other features if I can find that information from the essay columns. I did read these essays to determine if user dier was X."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use .loc to find specific essay string and fill 'diet' column with appropriate diet\n",
    "ok_cupid_df.loc[ok_cupid_df['essay0'] == \"im looking for someone to share some raging adhd. im a self motivated and light hearted superhero who enjoy's riding my bike everywhere and eating every goddamn thing i can.  im looking for someone to go adventuring with. i enjoy blind drunken adventures sometimes but you dont have to be a drinker. no vegans, i will eat anything... including people... especially hipsters. im not really a nerd (i don't play magic cards/excessive videogames) but i can like nerdy girls.  i just got this account, so gimmie some time to write down more shenanigans that are important  if u make chiptunes hit me the fuck up! i wanna make some!  i am awesome, eccentric, and energetic\", 'diet'] = 'strictly anything'\n",
    "\n",
    "ok_cupid_df.loc[ok_cupid_df['essay0'] == \"rabid bibliophile, humorless feminist (that's a joke), eternal student. i like to write poetry on people, bake (vegan) cupcakes, make art and dress-up.  i identify as queer but my choices here are limited so i chose bisexual.  i am quiet, empathetic, and geeky\", 'diet'] = 'vegan'\n",
    "\n",
    "ok_cupid_df.loc[ok_cupid_df['essay2'] == \"cooking all types of foods, caring for others, being very social and outgoing. i think i am really good at horseback riding it is one of my true passions even though i have not gone in a long time. singing in the shower is always a good time....lol.\", 'diet'] = 'anything'\n",
    "\n",
    "ok_cupid_df.loc[ok_cupid_df['essay2'] == 'writing and listening. in addition, i am an amazing troubleshooter. i thoroughly enjoy (and therefore have gotten good at) making people laugh, acting, bicycling, juggling, copy editing, computers... and lots more. - why does okcupid rate me \"less energetic\" than other guys? that\\'s kind of weird if you know me. i\\'m, like, chatty. plus i manufacture heat really well. i save on heating costs!  also, i\\'ve recently learned that i\\'m a good cook, mainly because i can follow a recipe. ask me about my unerring chicken & dumplings or my stupid good pot pie. it\\'s so easy when it\\'s easy!', 'diet'] = 'anything'\n",
    "\n",
    "ok_cupid_df.loc[ok_cupid_df['essay2'] == \"i'm a musician at heart and i'm great at playing the drums. i also love to cook, especially butter chicken.\", 'diet'] = 'anything'\n",
    "\n",
    "ok_cupid_df.loc[ok_cupid_df['essay2'] == \"eating chicken wings, shooting guns(recreational lol not at people) i'm actually pretty good at a lot if stuff it's just those first two are probably the most relevant lol :-) if you get to know me youll find out ;-) i'd say im a pretty interesting individual, but i know most of you lady's are basically looking at my photos and only that and couldn't give a dam about what i'm bout besides whether or not i'm making money..\", 'diet'] = 'anything'\n",
    "\n",
    "essay4_diet_string = ok_cupid_df[ok_cupid_df['diet'] == 'unknown_diet']['essay4'].tolist()[2]\n",
    "essay4_diet_string\n",
    "\n",
    "ok_cupid_df.loc[ok_cupid_df['essay4'] == essay4_diet_string, 'diet'] = 'anything'\n",
    "\n",
    "ok_cupid_df.loc[ok_cupid_df['essay4'] == \"one of my hobbies is making sushi.  overall i like most foods. one of my personal rules is to try things at least once, so i get to experience a lot of variety.  books: i have enjoyed harry potter series, da vinci code, and what i wish i knew when i was 20. i don't read as much as i would like to, but when i do i enjoy it.  i am open with music, i can find good music in any genre, even country, one can find good in even the worst. for the most part, i enjoy techno/dance, 80's rock (queen, bon jovi, scorpions), classic/jazz (sinatra, elvis, big bad voodoo daddy, red elvises), and current top charts. one of my favorite new discovery's have been apple trees & tangerines.  movies: i enjoy watching movies in theaters. one of my favorite is lord of war but the list includes; ferris bueler, sean connery movies (the rock, finding forester, hunt for red october, bond), indiana jones trilogy, quentin terantino flicks (pulp fiction, reservoir dogs, inglorious bastards, etc.). leonardo dicaprio has put himself in awesome roles since titanic, catch me if you can and the aviator. the brothers bloom. .\", 'diet'] = 'anything'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown_diet           18553\n",
       "mostly anything        13105\n",
       "anything                4810\n",
       "strictly anything       3654\n",
       "mostly vegetarian       2530\n",
       "mostly other             785\n",
       "strictly vegetarian      698\n",
       "vegetarian               450\n",
       "strictly other           333\n",
       "other                    257\n",
       "mostly vegan             252\n",
       "strictly vegan           182\n",
       "vegan                     97\n",
       "mostly kosher             70\n",
       "mostly halal              41\n",
       "strictly kosher           15\n",
       "strictly halal            15\n",
       "halal                     10\n",
       "kosher                     9\n",
       "Name: diet, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok_cupid_df['diet'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change unknown_diet to rather not say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rather not say         18553\n",
       "mostly anything        13105\n",
       "anything                4810\n",
       "strictly anything       3654\n",
       "mostly vegetarian       2530\n",
       "mostly other             785\n",
       "strictly vegetarian      698\n",
       "vegetarian               450\n",
       "strictly other           333\n",
       "other                    257\n",
       "mostly vegan             252\n",
       "strictly vegan           182\n",
       "vegan                     97\n",
       "mostly kosher             70\n",
       "mostly halal              41\n",
       "strictly kosher           15\n",
       "strictly halal            15\n",
       "halal                     10\n",
       "kosher                     9\n",
       "Name: diet, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find index of unknown_diet and replace with 'rather not say'\n",
    "ok_cupid_df['diet'] = ok_cupid_df['diet'].str.replace('unknown_diet', 'rather not say')\n",
    "ok_cupid_df['diet'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45866, 31)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok_cupid_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Status:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "single            42697\n",
       "seeing someone     1552\n",
       "available          1357\n",
       "married             254\n",
       "unknown               6\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok_cupid_df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace unknown with 'unknown_status' so it's more distinct\n",
    "ok_cupid_df[\"status\"].replace({'unknown': 'unknown_status'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_cupid_df.loc[ok_cupid_df['essay7'] == 'at home with my boy friend usually, listening to music on the i:pod in shuffle mode and painting', 'status'] = 'seeing someone'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop unknwon_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_status = ok_cupid_df[ok_cupid_df['status'] == 'unknown_status'].index\n",
    "ok_cupid_df.drop(index_status, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "single            42697\n",
       "seeing someone     1552\n",
       "available          1357\n",
       "married             254\n",
       "Name: status, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok_cupid_df['status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Body Type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "average              11653\n",
       "fit                   9413\n",
       "athletic              9116\n",
       "unknown_body_type     3589\n",
       "thin                  3580\n",
       "curvy                 3010\n",
       "a little extra        2169\n",
       "skinny                1392\n",
       "full figured           838\n",
       "overweight             368\n",
       "jacked                 309\n",
       "used up                256\n",
       "rather not say         167\n",
       "Name: body_type, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill nulls in body_type with unknown_body_type\n",
    "ok_cupid_df['body_type'] = ok_cupid_df['body_type'].fillna('unknown_body_type')\n",
    "ok_cupid_df['body_type'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill unknown_body_type with info from essay columns (similar to diet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_cupid_df.loc[ok_cupid_df['essay0'] == 'gainfully self-employed by day, amateur musician in my spare time, i play guitar and bass guitar ok, organ/ keyboards not so well. i sing and play in a band as a hobby. i read, tinker with electronics and mechanical stuff, write music and other stuff occasionally, in the little spare time my career affords me. i am fascinated with astronomy, but i\\'m not an expert astronomer. i did, however, enjoy building my own 8\" newtonian reflector telescope. i just like to set up and look at the moon, venus, jupiter, whatever i can find on any given night. i\\'m a \"blue-collar intellectual\", i suppose. i can fix anything. the things that i have left blank in my details are blank because there were no suitable multiple-choice answers. for body type, i would have to say; \"sturdy, stocky, strong as an ox\". my income varies because i\\'m self-employed. i\\'ll say; \"income: enough that i don\\'t have to watch my pennies, but not enough to get rich quick\". i have diverse interests, including astronomy, music, guitar, saxophone, organ, keyboard, electronics, antiques, camping, outdoors, commerce, and more!  i am sincere, spontaneous, and scatterbrained', 'body_type'] = 'rather not say'\n",
    "ok_cupid_df.loc[ok_cupid_df['essay0'] == 'sweet queer poly geeky kinky feminist liberal overly verbose cynical optimist with a dirty and dark sense of humor and fever dreams of polymathy iso... awesome people i haven\\'t met yet, for surprising and delicious and hilarious interactions across the spectrum of possibilities. (this legitimately and honestly includes new friends -- i\\'m not interested in filtering and discarding neat individuals out of my life just because there\\'s no mutual relationship chemistry.)  i consider \\'there\\'s no way to do that\\' a statement of challenge, not a concession to inevitability. i take sex both as intensely and as casually as it deserves. i don\\'t like losing, but i try very hard to be gracious when i do. i\\'ve got a sadly limited vocal range, but that doesn\\'t stop me from singing when the mood moves me. my pronunciation is irrevocably and curiously erroneous in amusing ways. i\\'m happiest when i\\'ve just made someone laugh -- the harder the better. my (white, male, financial) privilege is examined, and kept under recurring surveillance. i\\'ll try almost anything once, and on zero notice if my schedule is free.  (as for the body type self-summary in the details sidebar, i prefer \"stocky\", but that\\'s not an available option on the list, so it gets put here.)', 'body_type'] = 'rather not say'\n",
    "ok_cupid_df.loc[ok_cupid_df['essay0'] == 'i\\'m specifically looking to connect with those nearby* who have cultivated the ability to notice thought as it arises, and grok that thoughts aren\\'t personal. (*or near bos, nyc, hnl -- places i\\'ll be going to in the near future)  points of reference: rumi, yoda, tolle, ramana maharshi  gratitude, moments of noticing being both the ocean and a drop of water, easy laughter, embodied awareness/presence practices  fun-loving -- whether being deeply silent or raucously silly committed to serving the evolution of consciousness (and open to other ways of describing it) sometimes simultaneously grounded and expanded/ethereal  once in a while, i run; often dance. love to walk in forests, sit in forests, stand in forests, breathe in forests :) also have come to deeply appreciate the silence and magic of swimming with fishes, turtles, and the like. (i would say \"snorkeling,\" but i only use a mask.)  seem to have developed a green-ish thumb, and envision gardening more in the upcoming months.  a note about children -- for a while, wanted to adopt 10 and birth a couple; life unfurled differently: no biological children, and 2 sort-of-semi-stepdaughters who are now adults.  unsure what to put down for \"body type\" -- kinda fit, kinda not, kinda average, kinda thin = ? when seated, am taller than one of my 6\\' tall friends.', 'body_type'] = 'average'\n",
    "ok_cupid_df.loc[ok_cupid_df['essay0'] == \"i would describe my self as someone loves making people laugh and loves to follow their visions. i am generally into open relationships, queerdos and newcummers too. i am open to being in a closed relationships too if it feels right. oh ya and i am kinda poor, so don't expect me to buy you gifts all the time but you can expect me to warm your little tender boygirl heart with a cup of hot chocolate with marsh mellows inside. or show you a documentary on direct actions, or videos of circus and clowns.  i love movies, nature, kink, love making, radical faeries, cage fighting (for some gay reason), thrift shopping, being supportive, booty shaking fun time, sex positivity, all body type positivity. i am big bodied, wacky, muscular, cuddly, chewy, and have tattood hair and smile lines. i am loving, strange, sweet and have luscious lips. mwahahaha!\", 'body_type'] = 'curvy'\n",
    "ok_cupid_df.loc[ok_cupid_df['essay1'] == 'i am not afraid of working hard. but i am not defined by my work. trust me, i love to play! i have been very busy traveling over the past few years. i also like to keep myself busy by trying new activities. in the past i have trained for two century rides (100 mile bike rides) and in the past few months - since the end of 2011 - i have really gotten into crossfit (which is why i didn\\'t answer the body type question. there wasn\\'t an option for improving everyday-lol). i am also hoping to resume taking guitar lessons, if time allows this year. basically as the years go on, my \"bucket list\" keeps growing , and i keep trying to check things off of it. there doesn\\'t really seem to be any good place to add this, but i also love going to watch baseball games either at the park or local bars.', 'body_type'] = 'rather not say'\n",
    "ok_cupid_df.loc[ok_cupid_df['essay8'] == 'i didn\\'t pick a body type because \"fat kid with sticky fingers trapped inside\" wasn\\'t an option.', 'body_type'] = 'rather not say'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace remaining unknown_body_type with rather not say:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_cupid_df['body_type'] = ok_cupid_df['body_type'].str.replace('unknown_body_type', 'rather not say')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age             0.000000\n",
       "status          0.000000\n",
       "sex             0.000000\n",
       "orientation     0.000000\n",
       "body_type       0.000000\n",
       "diet            0.000000\n",
       "drinks          3.517226\n",
       "drugs           0.000000\n",
       "education      10.928914\n",
       "ethnicity       8.637157\n",
       "height          0.002181\n",
       "income          0.000000\n",
       "job            12.812909\n",
       "last_online     0.000000\n",
       "location        0.000000\n",
       "offspring      57.738770\n",
       "pets           33.185783\n",
       "religion       31.689926\n",
       "sign           18.118186\n",
       "smokes          5.994331\n",
       "speaks          0.054514\n",
       "essay0          9.498474\n",
       "essay1         13.279546\n",
       "essay2         16.761884\n",
       "essay3         19.156127\n",
       "essay4         18.587004\n",
       "essay5         18.556476\n",
       "essay6         23.826864\n",
       "essay7         21.046664\n",
       "essay8         32.810728\n",
       "essay9         21.829481\n",
       "dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok_cupid_df.isna().sum()/ok_cupid_df.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Education:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "graduated from college/university    17706\n",
       "graduated from masters program        7022\n",
       "unknown_education                     5012\n",
       "working on college/university         4595\n",
       "graduated from two-year college       1302\n",
       "working on masters program            1234\n",
       "graduated from high school            1223\n",
       "graduated from ph.d program           1028\n",
       "working on two-year college            921\n",
       "graduated from law school              804\n",
       "dropped out of college/university      778\n",
       "working on ph.d program                724\n",
       "college/university                     609\n",
       "graduated from space camp              498\n",
       "graduated from med school              370\n",
       "dropped out of space camp              361\n",
       "working on space camp                  304\n",
       "working on law school                  190\n",
       "two-year college                       186\n",
       "working on med school                  173\n",
       "dropped out of two-year college        154\n",
       "masters program                        105\n",
       "dropped out of masters program         103\n",
       "dropped out of ph.d program             94\n",
       "dropped out of high school              91\n",
       "high school                             87\n",
       "working on high school                  82\n",
       "space camp                              35\n",
       "ph.d program                            20\n",
       "law school                              15\n",
       "dropped out of law school               14\n",
       "med school                              10\n",
       "dropped out of med school               10\n",
       "Name: education, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fill null with unknown education\n",
    "ok_cupid_df['education'] = ok_cupid_df['education'].fillna('unknown_education')\n",
    "ok_cupid_df['education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age             0.000000\n",
       "status          0.000000\n",
       "sex             0.000000\n",
       "orientation     0.000000\n",
       "body_type       0.000000\n",
       "diet            0.000000\n",
       "drinks          1.938895\n",
       "drugs           0.000000\n",
       "education       0.000000\n",
       "ethnicity       7.689483\n",
       "height          0.000000\n",
       "income          0.000000\n",
       "job             8.622209\n",
       "last_online     0.000000\n",
       "location        0.000000\n",
       "offspring      56.225519\n",
       "pets           30.182628\n",
       "religion       28.446925\n",
       "sign           15.692323\n",
       "smokes          4.205836\n",
       "speaks          0.058754\n",
       "essay0          8.590384\n",
       "essay1         11.652957\n",
       "essay2         15.158637\n",
       "essay3         17.596945\n",
       "essay4         16.438993\n",
       "essay5         16.661770\n",
       "essay6         21.942323\n",
       "essay7         19.141696\n",
       "essay8         30.838719\n",
       "essay9         20.179691\n",
       "dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unknown education\n",
    "index_education = ok_cupid_df[ok_cupid_df['education'] == 'unknown_education'].index\n",
    "ok_cupid_df.drop(index_education, inplace = True)\n",
    "ok_cupid_df.isna().sum()/ok_cupid_df.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Job:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "other                                5345\n",
       "rather not say                       3852\n",
       "student                              3797\n",
       "science / tech / engineering         3530\n",
       "computer / hardware / software       3349\n",
       "sales / marketing / biz dev          3160\n",
       "artistic / musical / writer          3036\n",
       "medicine / health                    2725\n",
       "education / academia                 2577\n",
       "executive / management               1737\n",
       "banking / financial / real estate    1694\n",
       "entertainment / media                1474\n",
       "law / legal services                  947\n",
       "hospitality / travel                  944\n",
       "construction / craftsmanship          692\n",
       "clerical / administrative             583\n",
       "political / government                541\n",
       "transportation                        269\n",
       "unemployed                            227\n",
       "retired                               194\n",
       "military                              175\n",
       "Name: job, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok_cupid_df['job'] = ok_cupid_df['job'].fillna('rather not say')\n",
    "ok_cupid_df['job'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ethinicity:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "white                                                                       22526\n",
       "asian                                                                        4679\n",
       "unknown_ethnicity                                                            3141\n",
       "hispanic / latin                                                             1911\n",
       "black                                                                        1504\n",
       "                                                                            ...  \n",
       "black, native american, pacific islander, hispanic / latin, white, other        1\n",
       "middle eastern, black, native american, white, other                            1\n",
       "asian, middle eastern, black, white, other                                      1\n",
       "middle eastern, pacific islander, hispanic / latin                              1\n",
       "middle eastern, native american, hispanic / latin, white                        1\n",
       "Name: ethnicity, Length: 195, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok_cupid_df['ethnicity'] = ok_cupid_df['ethnicity'].fillna('unknown_ethnicity')\n",
    "ok_cupid_df['ethnicity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop rows with unknown ethnicity:\n",
    "index_ethnicity = ok_cupid_df[ok_cupid_df['ethnicity'] == 'unknown_ethnicity'].index\n",
    "ok_cupid_df.drop(index_ethnicity, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Offspring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown_offspring                          21067\n",
       "doesn't have kids                           4742\n",
       "doesn't have kids, but might want them      2712\n",
       "doesn't have kids, but wants them           2615\n",
       "doesn't want kids                           2022\n",
       "has kids                                    1346\n",
       "has a kid                                   1279\n",
       "doesn't have kids, and doesn't want any      793\n",
       "has kids, but doesn't want more              342\n",
       "has a kid, but doesn't want more             211\n",
       "has a kid, and might want more               169\n",
       "wants kids                                   144\n",
       "might want kids                              114\n",
       "has kids, and might want more                 79\n",
       "has a kid, and wants more                     52\n",
       "has kids, and wants more                      20\n",
       "Name: offspring, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok_cupid_df['offspring'] = ok_cupid_df['offspring'].fillna('unknown_offspring')\n",
    "ok_cupid_df['offspring'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age             0.000000\n",
       "status          0.000000\n",
       "sex             0.000000\n",
       "orientation     0.000000\n",
       "body_type       0.000000\n",
       "diet            0.000000\n",
       "drinks          0.991915\n",
       "drugs           0.000000\n",
       "education       0.000000\n",
       "ethnicity       0.000000\n",
       "height          0.000000\n",
       "income          0.000000\n",
       "job             0.000000\n",
       "last_online     0.000000\n",
       "location        0.000000\n",
       "offspring       0.000000\n",
       "pets            0.000000\n",
       "religion       22.443480\n",
       "sign           10.768828\n",
       "smokes          2.676299\n",
       "speaks          0.044917\n",
       "essay0          7.231622\n",
       "essay1          9.645905\n",
       "essay2         12.576733\n",
       "essay3         14.448271\n",
       "essay4         13.490043\n",
       "essay5         13.478814\n",
       "essay6         18.625543\n",
       "essay7         16.012876\n",
       "essay8         26.369966\n",
       "essay9         17.169486\n",
       "dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok_cupid_df['pets'] = ok_cupid_df['pets'].fillna('unknown_pets')\n",
    "\n",
    "index_pets = ok_cupid_df[ok_cupid_df['pets'] == 'unknown_pets'].index\n",
    "\n",
    "# drop rows with unknown pets\n",
    "ok_cupid_df.drop(index_pets, inplace = True)\n",
    "ok_cupid_df.isna().sum()/ok_cupid_df.shape[0]*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Religion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unknown_religion                              5996\n",
       "agnosticism but not too serious about it      1535\n",
       "catholicism but not too serious about it      1392\n",
       "agnosticism and laughing about it             1300\n",
       "other                                         1255\n",
       "agnosticism                                   1227\n",
       "christianity but not too serious about it     1219\n",
       "other and laughing about it                   1100\n",
       "atheism and laughing about it                 1050\n",
       "other but not too serious about it             956\n",
       "christianity                                   905\n",
       "atheism                                        881\n",
       "judaism but not too serious about it           773\n",
       "atheism but not too serious about it           674\n",
       "christianity and somewhat serious about it     581\n",
       "other and somewhat serious about it            498\n",
       "atheism and somewhat serious about it          481\n",
       "catholicism                                    441\n",
       "catholicism and laughing about it              412\n",
       "buddhism but not too serious about it          377\n",
       "christianity and very serious about it         351\n",
       "agnosticism and somewhat serious about it      348\n",
       "atheism and very serious about it              333\n",
       "catholicism and somewhat serious about it      326\n",
       "judaism and laughing about it                  315\n",
       "other and very serious about it                290\n",
       "buddhism and somewhat serious about it         228\n",
       "judaism                                        227\n",
       "christianity and laughing about it             216\n",
       "buddhism and laughing about it                 212\n",
       "agnosticism and very serious about it          157\n",
       "buddhism                                       146\n",
       "judaism and somewhat serious about it          145\n",
       "hinduism but not too serious about it           94\n",
       "catholicism and very serious about it           65\n",
       "buddhism and very serious about it              36\n",
       "hinduism and somewhat serious about it          31\n",
       "hinduism                                        30\n",
       "hinduism and laughing about it                  19\n",
       "islam but not too serious about it              19\n",
       "judaism and very serious about it               17\n",
       "islam                                           14\n",
       "islam and somewhat serious about it             14\n",
       "islam and laughing about it                     12\n",
       "hinduism and very serious about it              10\n",
       "islam and very serious about it                  8\n",
       "Name: religion, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ok_cupid_df['religion'] = ok_cupid_df['religion'].fillna('unknown_religion')\n",
    "ok_cupid_df['religion'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find religion from essay columns (similar to diet):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_cupid_df.loc[ok_cupid_df['essay0'] == \"i just have to say that internet dating is so weird. i love perusing these intimate little snapshots of all of you, and trying to imagine what it would be like to go out with you, or what your skin smells like, or how your face moves when you talk. and probably the imagination is more fun then the actual date. meaning, that undeniable chemistry that you feel when you meet someone is not something you can feel except within sight of that person. and btw i would really like to hear the scientific explanation for the way i can feel someone looking at me and raise my head and zero in on that person's face in two milliseconds without even having to look around. i already know exactly the coordinates of those eyes. what is that? but back to what i was saying, which is that this is really a poor substitute for meeting you in person. but, considering that most of the time i'm too busy to even read my damn personal email, i guess it will have to do. (update; it is much easier to keep up with email now that it is in my phone.)  i was raised atheist by scientists and now i go to church sometimes. i am dichotomous. i have been called little miss kick ass, and if there is one reason why i'm still single, i think it's probably summed up best by my chinese horoscope -- fire dragon.\", 'religion'] =  'christianity but not too serious about it'\n",
    "\n",
    "for essay in ok_cupid_df[(ok_cupid_df['religion'] == 'unknown_religion') & (ok_cupid_df['essay0'] != np.nan) & (ok_cupid_df['essay0'].str.contains(\"agnostic\"))]['essay0'].tolist():\n",
    "    ok_cupid_df.loc[ok_cupid_df['essay0'] == essay, 'religion'] = 'agnosticism'\n",
    "\n",
    "for essay in ok_cupid_df[(ok_cupid_df['religion'] == 'unknown_religion') & (ok_cupid_df['essay0'] != np.nan) & (ok_cupid_df['essay0'].str.contains(\"atheist\"))]['essay0'].tolist():\n",
    "    ok_cupid_df.loc[ok_cupid_df['essay0'] == essay, 'religion'] = 'atheism'\n",
    "\n",
    "ok_cupid_df.loc[ok_cupid_df['essay6'] == \"i'm an atheist. i am usually not a closeted anti-theist, but sometimes i am. i think this is it, but the notion of an afterlife, like many of the popular religions profess to, would be a pretty rad idea. unfortunately, faith alone, isn't a basis with which i wish to base this enticing concept. having said that, i'm generally a subscriber of the old adage, live life and let live. if it rains for 40 days and 40 nights i'm not going to start building an ark, but if you do, it's ok, as long as i get to laugh during construction time.\", 'religion'] =  'atheism'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save dataframe to be used in models notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ok_cupid_df.to_csv(r'data/okcupid_profiles_half_clean.csv', index = False, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
